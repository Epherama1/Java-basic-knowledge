冯·诺伊曼理论的要点是：计算机的数制采用二进制；计算机应该按照程序顺序执行。


计算机是一种数据处理设备，它由CPU和内存以及外部设备组成。CPU负责数据处理，内存负责存储，外部设备负责数据的输入和输出，它们之间通过总线连接在一起。
CPU内部主要由控制器、运算器和寄存器组成。控制器负责指令的读取和调度，运算器负责指令的运算执行，寄存器负责数据的存储，它们之间通过CPU内的总线连接在一起。
每个外部设备(例如：显示器、硬盘、键盘、鼠标、网卡等等)则是由外设控制器、I/O端口、和输入输出硬件组成。
外设控制器负责设备的控制和操作，I/O端口负责数据的临时存储，输入输出硬件则负责具体的输入输出，它们间也通过外部设备内的总线连接在一起。

指令周期（Instruction Cycle）：取出并执行一条指令的时间。
CPU周期：一条指令执行过程被划分为若干阶段，每一阶段完成所需时间。
时钟周期（Clock Cycle）：又称震荡周期，是处理操作的最基本单位。

计算机组成原理：
局部性原理: CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。
时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。
空间局部性（Spatial Locality）：在最近的将来将用到的信息很可能与正在使用的信息在空间地址上是临近的。


无内存抽象存在的问题：
用户程序可以访问任意内存，容易破坏操作系统，造成崩溃：
同时运行多个程序特别困难：当一个进程给内存地址1000赋值后，另一个进程也同样给内存地址赋值，那么第二个进程对内存的赋值会覆盖第一个进程所赋的值，这回造成两条进程同时崩溃。

每个进程都需要内存，Context Switch 时，之前内存里的内容怎么办？简单粗暴的方式就是先 dump 到磁盘上，然后再从磁盘上 restore 之前 dump 的内容（如果有的话），但效果并不好，太慢了！
那怎么才能不慢呢？把进程对应的内存依旧留在物理内存中，需要的时候就切换到特定的区域。这就涉及到了内存的保护机制，毕竟进程之间可以随意读取、写入内容就乱套了，非常不安全。


程序的局部性原理：高速缓存原理：
当CPU要访问主存时，实际上是把地址发给了Cache，最开始，Cache里面是没有数据的。
所以，Cache会把地址再发给主存，然后从主存中取得对应的数据，但Cache并不会只取回CPU当前需要的那个数据，而是会把与这个数据位置相邻的主存单元里的数据一并取回来，这些数据就称为一个数据块。
那么Cache会从主存里，取回这么一个数据块，存放在自己内部。然后，再选出CPU需要的那个数据送出去，那过一会儿，CPU很可能就会需要刚才那个数据附近的其它数据，这时候，这些数据已经在Cache当中了，就可以很快的返回，从而提升了访存的性能。
第二种情况，是Cache对时间局部性的利用。因为这个数据块暂时会保存在Cache当中，CPU如果要再次用到刚才用过的那个存储单元，Cache也可以很快的提供这个单元的数据

内存必须容纳操作系统和各种用户进程
内存通常分为两个区域，一个用于驻留操作系统，另一个用于用户进程。
操作系统可以位于低内存，也可以位于高内存，影响这一决定的主要因素是中断向量的位置，由于中断向量通常位于低内存，因此程序员通常将操作系统页放在低内存。
中断向量：中断标志码的表

一个进程的地址空间包含了该进程所有相关内存，比如 code / stack（本地变量、返回值） / heap（临时数据和动态数据结构）


内存保护：
内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。通过釆用重定位寄存器和界地址寄存器来实现这种保护。
重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址值。每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。
方法：
1.在CPU中设置一对下限寄存器和上限寄存器,存放用户作业在主存中的下限和上限地址
2.可将一个寄存器作为基址寄存器，另一寄存器作为限长寄存器（指示存储区长度）
当CPU调度器选择一个进程来执行时，作为上下文切换工作的一部分，调度程序会用正确的值来初始化重定位寄存器和界限地址寄存器。
每当CPU要访问主存，硬件自动将被访问的主存地址与界限寄存器的内容进行比较，以判断是否越界如果未越界，则按此地址访问主存，否则将产生程序中断——越界中断（存储保护中断）。
CPU 上用来做内存地址翻译的也会被叫做「内存管理单元 MMU」(Memory Management Unit)
base and bounds 这种做法最大的问题在于空间浪费，Stack 和 Heap 中间有一块 free space，即使没有用，也被占着。

内存分配：
1.可变分区：
操作系统有一个表,用于记录哪些内存可用和哪些内存已经被使用。
当有新进程需要内存时，为该进程查找足够大的孔，如果找到，可以从该进程分配所需的内存，孔内未分配的内存可以下次再用。
随着进程进入系统，它们将被加入到输入队列，操作系统根据所有进程的内存需要和现有可用内存情况来决定哪些进程可以分配内存。
当进程分配到空间时，它就装入内存，并开始竞争CPU，当进程终止的时候，它将释放内存，该内存可以被操作系统分配给输入队列中的其他进程。
内存不断地分配给进程，直到下一个进程的内存需求不能满足为止，这时没有足够大的可用孔来装入进程。操作系统可以等到有足够大的空间。或者往下扫描输入队列以确定是否有其他内存需求较小的进程可以被满足。
如果孔太大，那么就分为两块：一块分配新进程，另一块还回到集合。如果新孔与其他孔相邻，那么将这些孔合并成大孔。
分配方法：首次适应(first-fit)、最佳适应(best-fit)、最差适应(worst-fit)

碎片：空闲内存被分为小片段，当所有总的可用内存之和可以满足请求，但并不连续时，这就出现了外部碎片

解决碎片方法一：紧缩
紧缩的目的是移动内存内容，以便所有空间合并成一整块
如果重定位是静态的，并且在汇编时或装入市进行的，那么就不能紧缩。紧缩仅在重定位是动态并在运行时可采用。
开销较大

解决碎片方法二：分页
实现分页的基本方法涉及将物理内存分为固定大小的块: 称为帧(frame); 而将逻辑内存也分为同样大小的块,称为页(page)。
当需要执行进程时，其页从备份存储中调入到可用的内存帧中，备份存储页分为固定大小的块，其大小与内存帧一样。
由CPU生成的每个地址分为两部分: 页号(p) 和页偏移(d)。页号作为页表中的索引。页表包含每页所在物理内存的基地址，这些基地址与页偏移的组合就形成了物理地址，就可送交物理单元。

虚拟内存：
内存管理策略都是为同一目的：同时将多个进程存放在内存中，以便允许多道程序设计，不过这些策略都需要在进程执行之前将这个进程放进内存中。
虚拟内存技术允许执行进程不必完全在内存中，这种方案的一个显著的优点就是程序可以比物理内存大

在许多情况下并不需要将整个程序放到内存中：
程序通常有处理异常错误条件的代码，由于这些错误即使有也是很少发生，所以这中代码几乎不执行。
数组、链表和表通常分配了比实际所需要的更多的内存。
程序的某些选项或功能很少使用。

虚拟内存好处：
程序不再受现有的物理内存空间限制。用户可以为一个巨大的虚拟地址空间( address space)编写程序。简化了编程工作量。
因为每个用户程序使用了更少的物理内存，所以更多的程序可以同时执行，CPU使用率也相应增加，而响应时间或周转时间并不增加。
由于载入或交换每个用户程序到内存所需的I/O会更少，用户程序会运行得更快




一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核
Linux 的系统调用主要有以下这些：
进程控制	fork(); exit(); wait();
进程通信	pipe(); shmget(); mmap();
文件操作	open(); read(); write();
设备操作	ioctl(); read(); write();
信息维护	getpid(); alarm(); sleep();
安全	chmod(); umask(); chown();

编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」。

进程的五种状态：https://oscimg.oschina.net/oscnet/11f3575697027da09801c5f963e88d87db5.png
挂起状态可以分为两种：由于虚拟内存管理原因，进程的所使用的空间可能并没有映射到物理内存，而是在硬盘上
阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

PCB 是进程存在的唯一标识：
进程描述信息：
进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；
进程控制和管理信息：
进程当前状态，如 new、ready、running、waiting 或 blocked 等；
进程优先级：进程抢占 CPU 时的优先级；
资源分配清单：
有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。
CPU 相关信息：
CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

PCB通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。除了链接的组织方式，还有索引方式。

01创建进程
操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时同时也会终止其所有的子进程。
创建进程的过程如下：
为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB，PCB 是有限的，若申请失败则创建失败；
为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源；
初始化 PCB；
如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行；

02 终止进程
进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。
终止进程的过程如下：
查找需要终止的进程的 PCB；
如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
如果其还有子进程，则应将其所有子进程终止；
将该进程所拥有的全部资源都归还给父进程或操作系统；
将其从 PCB 所在队列中删除；

03 阻塞进程
当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。
阻塞进程的过程如下：
找到将要被阻塞进程标识号对应的 PCB；
如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
将该 PCB 插入的阻塞队列中去；

04 唤醒进程
进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。
如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。
唤醒进程的过程如下：
在该事件的阻塞队列中找到相应进程的 PCB；
将其从阻塞队列中移出，并置其状态为就绪状态；
把该 PCB 插入到就绪队列中，等待调度程序调度；

CPU上下文切换：
操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。
CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

进程上下文切换：
进程是由内核管理和调度的，所以进程的切换只能发生在内核态。
所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。
进程上下文切换场景：
为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行；
进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；
当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；
当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；

线程：
同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程都有独立一套的寄存器和栈，这样可以确保线程的控制流是相对独立的。

一个线程崩溃对整个进程的影响：
当进程中的一个线程奔溃时，会导致其所属进程的所有线程奔溃。
一般来说，每个线程都是独立执行的单位，每个线程都有自己的上下文堆栈，一个线程的的崩溃不会对其他线程造成影响。
但是通常情况下，一个线程崩溃会产生一个进程内的错误，例如在linux操作系统中，可能会产生一个segment fault错误，
这个错误会产生一个信号，操作系统默认对这个信号的处理就是关闭进程，整个进程都被销毁了，这样的话这个进程中存在的其他线程自然也就不存在了。

多个用户级线程，因为在内核里这些用户级线程都属于同一个进程会被统一调度，这就导致若其中一个用户级线程卡住，会使得内核发生进程调度，CPU转而去执行另一个进程，这就使得原进程的所有用户级线程全都卡住。

线程与进程的比较如下：
进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；线程是调度的基本单位，而进程则是资源拥有的基本单位。
进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
线程能减少并发执行的时间和空间开销；

线程相比进程能减少开销，体现在：
线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；





进程管理：
通信方面进程和线程的区别：
线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

进程间通信方式：https://blog.csdn.net/J080624/article/details/87454764
根据进程通信时信息量大小的不同,可以将进程通信划分为两大类型:
低级通信：控制信息的通信(主要用于进程之间的同步,互斥,终止和挂起等等控制信息的传递)
高级通信：大批数据信息的通信(主要用于进程间数据块数据的交换和共享,常见的高级通信有管道,消息队列,共享内存等)。

1.管道通信：
一个进程在管道的尾部写入数据，另一个进程从管道的头部读出数据。管道包括无名管道和有名管道两种，前者只能用于父进程和子进程间的通信，后者可用于运行于同一系统中的任意两个进程间的通信。

管道通信特点： 
1. 管道通讯是单向的，有固定的读端和写端。 
2. 数据被进程从管道读出后，在管道中该数据就不存在了。 
3. 当进程去读取空管道的时候，进程会阻塞。 
4. 当进程往满管道写入数据时，进程会阻塞。 
5. 管道容量为64KB（#define PIPE_BUFFERS 16 include/linux/pipe_fs_i.h）

无名管道（pipe）：
是 UNIX 系统IPC最古老的形式，是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。
在Linux系统中，无名管道一旦创建完成后，操作无名管道等同于操作文件。无名管道的读端被视作一个文件；无名管道的写端也被视作一个文件。因此可以使用read，write，close等文件操作函数来访问无名管道。
有名管道（FIFO）：
有名管道又称为FIFO文件（先进先出），因此我们对有名管道的操作也可以采用操作文件的方法，如使用open，read，write等。可用于运行于同一系统中的任意两个进程间的通信。
FIFO文件对比普通文件： 
FIFO文件在使用上和普通文件有相似之处，但是也有 不同之处： 
1. 读取Fifo文件的进程只能以”RDONLY”方式打开fifo文件。 
2. 写Fifo文件的进程只能以”WRONLY”方式打开fifo文件。 
3. Fifo文件里面的内容被读取后，就消失了。但是普通文件里面的内容读取后还存在。

2.消息队列：
消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

消息队列的主要特点是异步处理，主要目的是减少请求响应时间和解耦。所以主要的使用场景就是将比较耗时而且不需要即时（同步）返回结果的操作作为消息放入消息队列。
消息队列场景：异步、削峰、解耦
异步：
流程里面多100ms去扣减优惠券，流程里面多了200ms去增减积分，100ms去发个短信。
再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms
那为什么不用线程池来实现异步：耦合：
A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？
全部都写在一起的话，耦合，出问题排查麻烦，流程里面随便一个地方出问题会影响到其他的点
你下单了，你就把你支付成功的消息告诉别的系统，他们收到了去处理就好了
削峰：
秒杀：把请求放到队列里面，然后至于每秒消费多少请求，就看自己的服务器处理能力。可能会比正常的慢一点，但是不至于打挂服务器，等流量高峰下去了，你的服务也就没压力了。
消息队列缺点：
系统复杂性：
凭空接入一个中间件在那，要去维护他，各种问题：消息重复消费、消息丢失、消息的顺序消费等等     ？？？这些问题是啥？
数据一致性：
分布式事务：把下单，优惠券，积分...都放在一个事务里面一样，要成功一起成功，要失败一起失败。Kafka，RabbitMQ

3.共享内存：
共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。
共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。

4.信号(Signal)和信号量(semaphore)

5.套接字(Socket)：
更为一般的进程间通信机制，可用于不同机器之间的进程间通信。

linux下的进程包含以下几个关键要素：
有一段可执行程序；
有专用的系统堆栈空间；
内核中有它的控制块（进程控制块），描述进程所占用的资源，这样，进程才能接受内核的调度；
具有独立的存储空间

线程间同步：
线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。
1. 锁机制：互斥锁、条件变量、读写锁和自旋锁。
2. 信号机制(Signal)和信号量机制(Semaphore)。
3. violate全局变量-共享内存
4. wait/notify：如何才能在当前线程还没退出synchronized数据块时让其他线程也有机会访问共享数据呢？
5. join()
6. CountDownLatch
7. CyclicBarrier
8. 线程池

保证线程安全手段：
同步机制：监视器锁(synchronized)、显示锁(ReentrantLock、RReadWriteLock)、原子变量(AtomicInteger/AtomciLong)、Volatile；
栈封闭：ThreadLocal
对象创建后不可更改。

ThreadLocal：
每个使用该变量的线程都会初始化一个完全独立的实例副本。
因为每个 Thread 内有自己的实例副本，且该副本只能由当前 Thread 使用。这是也是 ThreadLocal 命名的由来
既然每个 Thread 有自己的实例副本，且其它 Thread 不可访问，那就不存在多线程间共享的问题
每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal->value 键值对插入到该 Map 中。


yield方法与sleep方法区别说明如下：
sleep 方法使当前运行中的线程睡眠一段时间，进入不可以运行状态(停滞状态-waiting)，这段时间的长短是由程序设定的 ;
sleep方法和join方法都可以使低优先级线程获得执行机会，但是yield方法不能使低优先级线程获得执行机会；
yield方法使当前线程让出CPU占有权，但让出的时间是不可设定的 ;
yield方法与sleep不同的是，会使线程处于就绪状态，可能下一秒就被执行；
yield和sleep都不会释放对象锁标志，wait会释放锁。

sleep与wait区别：
sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，给执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。
wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。

以下情况将会释放锁：
当前线程的同步方法、同步代码块执行结束。
当前线程在同步代码块、同步方法中遇到break、return终止了该代码块、该方法的继续执行。
当前线程在同步代码块、同步方法中出现了未处理的Error或Exception，导致异常结束。
当前线程在同步代码块、同步方法中执行了线程对象的wait()方法，当前线程暂停，并释放锁(sleep不会释放锁)。
以下情况不会释放锁：
线程执行同步代码块或同步方法时，程序调用Thread.sleep()、Thread.yield()方法暂停当前线程的执行。
线程执行同步代码块时，其他线程调用了该线程的suspend()方法将该线程挂起，该线程不会释放锁（同步监视器）。

死锁：
不同的线程分别占用对方需要的同步资源不放弃，都在等待对方放弃自己需要的同步资源，就形成了线程的死锁。

进程切换：
1.为什么分内核态和用户态：
假设没有这种内核态和用户态之分，程序随随便便就能访问硬件资源，比如说分配内存，程序能随意的读写所有的内存空间，如果程序员一不小心将不适当的内容写到了不该写的地方，就很可能导致系统崩溃。
用户程序进行系统调用后，操作系统执行一系列的检查验证，确保这次调用是安全的，再进行相应的资源访问操作。内核态能有效保护硬件资源的安全。

PCB是OS为了系统的描述和管理进程的运行，在内核中为每个进程专门定义的一个数据结构：
1. 进程标识符：用于唯一地标识进程。一个进程通常包含两种标识符：外部标识符和内部标识符。
外部标识符一般由创建者（用户）提供，用来方便记忆；内部标识是为了方便OS对进程的使用，通常是Linux系统中查看到的Pid；
2. CPU状态：CPU状态信息也称处理机的上下文，主要由CPU的各种寄存器（通用寄存器、指令计数器、程序状态字PSW、用户栈指针）中的内容组成的。
进程在执行的过程中，正在处理的许多信息都放在寄存器中，如果需要发生切换，这些信息就需要保存在该进程的PCB中，以便可以再次执行时可以快速的恢复CPU的状态；
3. 进程调度信息：在OS进行调度（从就绪队列中选取进程分配CPU）时，必须要知道进程的状态和相关的调度信息，
主要包括：进程状态、优先级、进程调度所需的其他信息（等待时间、已经执行的时间等）、事件（等待发生的时间，即阻塞的原因）；
4. 进程的控制信息：只用于进程控制所必需的信息，主要包括：
程序和数据的地址（所在内存或外存的首地址）、进程同步和通信机制、资源清单（进程运行期间所需的全部资源，CPU除外，还有一张已经分配给该进程的资源清单，主要用于避免死锁）、链接指针（指向本PCB所在队列中的下一个进程的PCB的首地址）。




进程调度算法：
1. 批处理系统
批处理系统没有太多的用户操作，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。      吞吐量和周转时间？？？
1.1 先来先服务 first-come first-serverd（FCFS）：按照请求的顺序进行调度。
非抢占式的调度算法，有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

1.2 短作业优先 shortest job first（SJF）
非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

1.3 最短剩余时间优先 shortest remaining time next（SRTN）
最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

2. 交互式系统
交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。
2.1 时间片轮转
将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。
当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。
时间片轮转算法的效率和时间片的大小有很大关系：
因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
而如果时间片过长，那么实时性就不能得到保证。

2.2 优先级调度
为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

2.3 多级反馈队列
一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。
进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。
可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

信号量临界区保护，实现生产者消费者问题？？？？？？

经典同步问题：
1.生产者消费者问题    ？？？
2.哲学家进餐问题：哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。
3.读者-写者问题：允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

死锁形成的必要条件：
互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
占有和等待：已经得到了某个资源的进程可以再请求新的资源。
不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

死锁处理方法：
鸵鸟策略
死锁检测与死锁恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。
死锁预防：在程序运行之前预防发生死锁。
死锁避免：在程序运行时避免发生死锁。1. 安全状态。2.银行家算法

java线程是混合型的线程模型：
1、证明java线程不是纯粹用户级线程：java中有个fork join框架，这个框架是利用多处理技术进行maprudce的工作，也就证明了内核是可以感知到用户线程的存在，因此才会将多个线程调度到多个处理器中。
还有，java应用程序中的某个线程阻塞，是不会引起整个进程的阻塞，从这两点看，java线程绝不是纯粹的用户级线程。 
2、再来，证明java线程不是纯粹内核级线程：这点比较直观，如果使用纯粹的内核级线程，那么有关线程的所有管理工作都是内核完成的，用户程序中没有管理线程的代码。
显然，java线程库提供了大量的线程管理机制，因此java线程绝不是纯粹的内核级线程。 综上，java线程是混合型的线程模型，一般而言是通过lwp将用户级线程映射到内核线程中。



32位与64位的区别：
1、处理数据的能力
32位和64位表示CPU一次能处理的最大位数，64位系统处理的数据效率比32位更高，相当于 单车道和双车道开车似得，双车道单位时间可以有更多的车辆通行。但需要内存跟上，而且程序本身也是64位编译才能发挥64位系统的优势。
2、支持的内存不同（寻址能力不同）
寻址能力是指，电脑能在多大的空间里（内存）找到一个软件的数据被存放在哪里。
32位系统的最大寻址空间是2的32次方，4（GB）左右；而64位系统的最大寻址空间为2的64次方，数值大于1亿GB。不过那也只是理论值而已，实际使用过程中大多数的电脑32位系统最多识别3.5GB内存，64位系统最多识别128GB内存。
3、软件兼容性
32位系统无法运行64位软件，64位系统可以安装多数32位软件，以前因为大部分软件都是基于32位架构环境下开发，所以64位系统的兼容性不如32位。





